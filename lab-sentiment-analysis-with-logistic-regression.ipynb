{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Logistic Regression\n",
    "You will learn about logistic regression. Concretely, you will be implementing logistic regression for sentiment analysis on tweets. Given a tweet, you will decide if it has a positive sentiment or a negative one. Specifically you will: \n",
    "\n",
    "* Learn how to extract features for logistic regression given some text\n",
    "* Implement logistic regression from scratch\n",
    "* Apply logistic regression on a natural language processing task\n",
    "* Test using your logistic regression\n",
    "* Perform error analysis\n",
    "\n",
    "We will be using a data set of tweets. Hopefully you will get more than 99% accuracy.  \n",
    "Run the cell below to load in the packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import functions and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to import nltk\n",
    "import nltk\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/paulle/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/paulle/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imported functions\n",
    "\n",
    "Download the data needed for this assignment. Check out the [documentation for the twitter_samples dataset](http://www.nltk.org/howto/twitter.html).\n",
    "\n",
    "* twitter_samples: if you're running this notebook on your local computer, you will need to download it using:\n",
    "```Python\n",
    "nltk.download('twitter_samples')\n",
    "```\n",
    "\n",
    "* stopwords: if you're running this notebook on your local computer, you will need to download it using:\n",
    "```python\n",
    "nltk.download('stopwords')\n",
    "```\n",
    "\n",
    "#### Import some helper functions that we provided in the utils.py file:\n",
    "* `process_tweet()`: cleans the text, tokenizes it into separate words, removes stopwords, and converts words to stems.\n",
    "* `build_freqs()`: this counts how often a word in the 'corpus' (the entire set of tweets) was associated with a positive label '1' or a negative label '0', then builds the `freqs` dictionary, where each key is a (word,label) tuple, and the value is the count of its frequency within the corpus of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add folder, tmp2, from our local workspace containing pre-downloaded corpora files to nltk's data path\n",
    "# this enables importing of these files without downloading it again when we refresh our workspace\n",
    "\n",
    "filePath = f\"{getcwd()}/../tmp2/\"\n",
    "nltk.data.path.append(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples \n",
    "\n",
    "from utils import process_tweet, build_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "* The `twitter_samples` contains subsets of 5,000 positive tweets, 5,000 negative tweets, and the full set of 10,000 tweets.  \n",
    "    * If you used all three datasets, we would introduce duplicates of the positive tweets and negative tweets.  \n",
    "    * You will select just the five thousand positive tweets and five thousand negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train test split: 20% will be in the test set, and 80% in the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into two pieces, one for training and one for testing (validation set) \n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pos)\n",
    "len(test_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the numpy array of positive labels and negative labels. Je maakt hier een binary classificatie aan tussen positief en negatief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine positive and negative labels\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y.shape = (8000, 1)\n",
      "test_y.shape = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape train and test sets\n",
    "print(\"train_y.shape = \" + str(train_y.shape))\n",
    "print(\"test_y.shape = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y values:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"train_y values:\")\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the frequency dictionary using the imported `build_freqs()` function.  \n",
    "    * We highly recommend that you open `utils.py` and read the `build_freqs()` function to understand what it is doing.\n",
    "    * To view the file directory, go to the menu and click File->Open.\n",
    "\n",
    "```Python\n",
    "    for y,tweet in zip(ys, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "```\n",
    "* Notice how the outer for loop goes through each tweet, and the inner for loop steps through each word in a tweet.\n",
    "* The `freqs` dictionary is the frequency dictionary that's being built. \n",
    "* The key is the tuple (word, label), such as (\"happy\",1) or (\"happy\",0).  The value stored for each key is the count of how many times the word \"happy\" was associated with a positive label, or how many times \"happy\" was associated with a negative label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs) = 11337\n"
     ]
    }
   ],
   "source": [
    "# create frequency dictionary\n",
    "freqs = build_freqs(train_x, train_y)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs) = \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```\n",
    "type(freqs) = <class 'dict'>\n",
    "len(freqs) = 11346\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process tweet\n",
    "The given function `process_tweet()` tokenizes the tweet into individual words, removes stop words and applies stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of a positive tweet: \n",
      " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
      "\n",
      "This is an example of the processed version of the tweet: \n",
      " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
     ]
    }
   ],
   "source": [
    "# test the function below\n",
    "print('This is an example of a positive tweet: \\n', train_x[0])\n",
    "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```\n",
    "This is an example of a positive tweet: \n",
    " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
    " \n",
    "This is an example of the processes version: \n",
    " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Logistic regression \n",
    "\n",
    "\n",
    "### Part 1.1: Sigmoid\n",
    "You will learn to use logistic regression for text classification. \n",
    "* The sigmoid function is defined as: \n",
    "\n",
    "$$ h(z) = \\frac{1}{1+\\exp^{-z}} \\tag{1}$$\n",
    "\n",
    "It maps the input 'z' to a value that ranges between 0 and 1, and so it can be treated as a probability. \n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='./img/sigmoid_plot.jpg' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:300px;height:200px;\" /> Figure 1 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions: Implement the sigmoid function\n",
    "* You will want this function to work if z is a scalar as well as if it is an array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li><a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html\" > numpy.exp </a> </li>\n",
    "\n",
    "</ul>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def sigmoid(z): \n",
    "    '''\n",
    "    Input:\n",
    "        z: is the input (can be a scalar or an array)\n",
    "    Output:\n",
    "        h: the sigmoid of z\n",
    "    '''\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # calculate the sigmoid of z\n",
    "    h = 1 / (1+ np.exp(-z))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS!\n",
      "CORRECT!\n"
     ]
    }
   ],
   "source": [
    "# Testing your function \n",
    "if (sigmoid(0) == 0.5):\n",
    "    print('SUCCESS!')\n",
    "else:\n",
    "    print('Oops!')\n",
    "\n",
    "if (sigmoid(4.92) == 0.9927537604041685):\n",
    "    print('CORRECT!')\n",
    "else:\n",
    "    print('Oops again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression: regression and a sigmoid\n",
    "\n",
    "Logistic regression takes a regular linear regression, and applies a sigmoid to the output of the linear regression.\n",
    "\n",
    "Regression:\n",
    "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
    "Note that the $\\theta$ values are \"weights\". If you took the Deep Learning Specialization, we referred to the weights with the `w` vector.  In this course, we're using a different variable $\\theta$ to refer to the weights.\n",
    "\n",
    "Logistic regression\n",
    "$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n",
    "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
    "We will refer to 'z' as the 'logits'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Cost function and Gradient\n",
    "\n",
    "The cost function used for logistic regression is the average of the log loss across all training examples:\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)}))\\tag{5} $$\n",
    "* $m$ is the number of training examples\n",
    "* $y^{(i)}$ is the actual label of the i-th training example.\n",
    "* $h(z(\\theta)^{(i)})$ is the model's prediction for the i-th training example.\n",
    "\n",
    "The loss function for a single training example is\n",
    "$$ Loss = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$\n",
    "\n",
    "* All the $h$ values are between 0 and 1, so the logs will be negative. That is the reason for the factor of -1 applied to the sum of the two loss terms.\n",
    "* Note that when the model predicts 1 ($h(z(\\theta)) = 1$) and the label $y$ is also 1, the loss for that training example is 0. \n",
    "* Similarly, when the model predicts 0 ($h(z(\\theta)) = 0$) and the actual label is also 0, the loss for that training example is 0. \n",
    "* However, when the model prediction is close to 1 ($h(z(\\theta)) = 0.9999$) and the label is 0, the second term of the log loss becomes a large negative number, which is then multiplied by the overall factor of -1 to convert it to a positive loss value. $-1 \\times (1 - 0) \\times log(1 - 0.9999) \\approx 9.2$ The closer the model prediction gets to 1, the larger the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210340371976294"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that when the model predicts close to 1, but the actual label is 0, the loss is a large positive value\n",
    "-1 * (1 - 0) * np.log(1 - 0.9999) # loss is about 9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Likewise, if the model predicts close to 0 ($h(z) = 0.0001$) but the actual label is 1, the first term in the loss function becomes a large number: $-1 \\times log(0.0001) \\approx 9.2$.  The closer the prediction is to zero, the larger the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210340371976182"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that when the model predicts close to 0 but the actual label is 1, the loss is a large positive value\n",
    "-1 * np.log(0.0001) # loss is about 9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the weights\n",
    "\n",
    "To update your weight vector $\\theta$, you will apply gradient descent to iteratively improve your model's predictions.  \n",
    "The gradient of the cost function $J$ with respect to one of the weights $\\theta_j$ is:\n",
    "\n",
    "$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)}-y^{(i)})x_j \\tag{5}$$\n",
    "* 'i' is the index across all 'm' training examples.\n",
    "* 'j' is the index of the weight $\\theta_j$, so $x_j$ is the feature associated with weight $\\theta_j$\n",
    "\n",
    "* To update the weight $\\theta_j$, we adjust it by subtracting a fraction of the gradient determined by $\\alpha$:\n",
    "$$\\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j}J(\\theta) $$\n",
    "* The learning rate $\\alpha$ is a value that we choose to control how big a single update will be.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions: Implement gradient descent function\n",
    "* The number of iterations `num_iters` is the number of times that you'll use the entire training set.\n",
    "* For each iteration, you'll calculate the cost function using all training examples (there are `m` training examples), and for all features.\n",
    "* Instead of updating a single weight $\\theta_i$ at a time, we can update all the weights in the column vector:  \n",
    "$$\\mathbf{\\theta} = \\begin{pmatrix}\n",
    "\\theta_0\n",
    "\\\\\n",
    "\\theta_1\n",
    "\\\\ \n",
    "\\theta_2 \n",
    "\\\\ \n",
    "\\vdots\n",
    "\\\\ \n",
    "\\theta_n\n",
    "\\end{pmatrix}$$\n",
    "* $\\mathbf{\\theta}$ has dimensions (n+1, 1), where 'n' is the number of features, and there is one more element for the bias term $\\theta_0$ (note that the corresponding feature value $\\mathbf{x_0}$ is 1).\n",
    "* The 'logits', 'z', are calculated by multiplying the feature matrix 'x' with the weight vector 'theta'.  $z = \\mathbf{x}\\mathbf{\\theta}$\n",
    "    * $\\mathbf{x}$ has dimensions (m, n+1) \n",
    "    * $\\mathbf{\\theta}$: has dimensions (n+1, 1)\n",
    "    * $\\mathbf{z}$: has dimensions (m, 1)\n",
    "* The prediction 'h', is calculated by applying the sigmoid to each element in 'z': $h(z) = sigmoid(z)$, and has dimensions (m,1).\n",
    "* The cost function $J$ is calculated by taking the dot product of the vectors 'y' and 'log(h)'.  Since both 'y' and 'h' are column vectors (m,1), transpose the vector to the left, so that matrix multiplication of a row vector with column vector performs the dot product.\n",
    "$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n",
    "* The update of theta is also vectorized.  Because the dimensions of $\\mathbf{x}$ are (m, n+1), and both $\\mathbf{h}$ and $\\mathbf{y}$ are (m, 1), we need to transpose the $\\mathbf{x}$ and place it on the left in order to perform matrix multiplication, which then yields the (n+1, 1) answer we need:\n",
    "$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>use np.dot for matrix multiplication.</li>\n",
    "    <li>To ensure that the fraction -1/m is a decimal value, cast either the numerator or denominator (or both), like `float(1)`, or write `1.` for the float version of 1. </li>\n",
    "</ul>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        J: the final cost\n",
    "        theta: your final weight vector\n",
    "    Hint: you might want to print the cost to make sure that it is going down.\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # get 'm', the number of rows in matrix x\n",
    "    m = len(x)\n",
    "    \n",
    "    ## number of steps (num_iters)\n",
    "    for i in range(0, num_iters):\n",
    "        \n",
    "        # get z, the dot product of x and theta\n",
    "        z = np.dot(x, theta)\n",
    "        \n",
    "        # get the sigmoid of z. only for linear.\n",
    "        h = 1 / (1+ np.exp(-1))\n",
    "        \n",
    "        # calculate the cost function\n",
    "        J = (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "\n",
    "        # update the weights theta\n",
    "        theta = theta - (alpha / m) * np.dot(x.T, (h - y))\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.71326169.\n",
      "The resulting vector of weights is [-9.2e-07, -0.00022732, -0.00120065]\n"
     ]
    }
   ],
   "source": [
    "# Check the function\n",
    "# Construct a synthetic test case using numpy PRNG functions\n",
    "np.random.seed(1)\n",
    "# X input is 10 x 3 with ones for the bias terms\n",
    "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
    "# Y Labels are 10 x 1\n",
    "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
    "\n",
    "# Apply gradient descent\n",
    "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
    "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```\n",
    "The cost after training is 0.67094970.\n",
    "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Extracting the features\n",
    "\n",
    "* Given a list of tweets, extract the features and store them in a matrix. You will extract two features.\n",
    "    * The first feature is the number of positive words in a tweet.\n",
    "    * The second feature is the number of negative words in a tweet. \n",
    "* Then train your logistic regression classifier on these features.\n",
    "* Test the classifier on a validation set. \n",
    "\n",
    "### Instructions: Implement the extract_features function. \n",
    "* This function takes in a single tweet.\n",
    "* Process the tweet using the imported `process_tweet()` function and save the list of tweet words.\n",
    "* Loop through each word in the list of processed words\n",
    "    * For each word, check the `freqs` dictionary for the count when that word has a positive '1' label. (Check for the key (word, 1.0)\n",
    "    * Do the same for the count for when the word is associated with the negative label '0'. (Check for the key (word, 0.0).)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>Make sure you handle cases when the (word, label) key is not found in the dictionary. </li>\n",
    "    <li> Search the web for hints about using the `.get()` method of a Python dictionary.  Here is an <a href=\"https://www.programiz.com/python-programming/methods/dictionary/get\" > example </a> </li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def extract_features(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words for one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1 \n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        x[0,1] += freqs.get((word, 1), 0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word, 0), 0)\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e+00 3.02e+03 6.10e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Check your function\n",
    "\n",
    "# test 1\n",
    "# test on training data\n",
    "tmp1 = extract_features(train_x[0], freqs)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```\n",
    "[[1.00e+00 3.02e+03 6.10e+01]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# test 2:\n",
    "# check for when the words are not in the freqs dictionary\n",
    "tmp2 = extract_features('blorb bleeeeb bloooob', freqs)\n",
    "print(tmp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```\n",
    "[[1. 0. 0.]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training Your Model\n",
    "\n",
    "To train the model:\n",
    "* Stack the features for all training examples into a matrix `X`. \n",
    "* Call `gradientDescent`, which you've implemented above.\n",
    "\n",
    "This section is given to you.  Please read it for understanding and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.81326169.\n",
      "The resulting vector of weights is [-3.5e-07, 0.00038555, -0.00197155]\n"
     ]
    }
   ],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y\n",
    "\n",
    "# Apply gradient descent\n",
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "The cost after training is 0.24216529.\n",
    "The resulting vector of weights is [7e-08, 0.0005239, -0.00055517]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Test your logistic regression\n",
    "\n",
    "It is time for you to test your logistic regression function on some new input that your model has not seen before. \n",
    "\n",
    "#### Instructions: Write `predict_tweet`\n",
    "Predict whether a tweet is positive or negative.\n",
    "\n",
    "* Given a tweet, process it, then extract the features.\n",
    "* Apply the model's learned weights on the features to get the logits.\n",
    "* Apply the sigmoid to the logits to get the prediction (a value between 0 and 1).\n",
    "\n",
    "$$y_{pred} = sigmoid(\\mathbf{x} \\cdot \\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def predict_tweet(tweet, freqs, theta):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    Output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features(tweet, freqs)\n",
    "    \n",
    "    # make the prediction using x and theta\n",
    "    y_pred = sigmoid(np.dot(x, theta))\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy -> 0.506646\n",
      "I am bad -> 0.474755\n",
      "this movie should have been great. -> 0.498782\n",
      "great -> 0.505522\n",
      "great great -> 0.511044\n",
      "great great great -> 0.516562\n",
      "great great great great -> 0.522077\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to test your function\n",
    "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
    "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "```\n",
    "I am happy -> 0.518580\n",
    "I am bad -> 0.494339\n",
    "this movie should have been great. -> 0.515331\n",
    "great -> 0.515464\n",
    "great great -> 0.530898\n",
    "great great great -> 0.546273\n",
    "great great great great -> 0.561561\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7484061]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feel free to check the sentiment of your own tweet below\n",
    "my_tweet = 'I am learning :)'\n",
    "predict_tweet(my_tweet, freqs, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check performance using the test set\n",
    "After training your model using the training set above, check how your model might perform on real, unseen data, by testing it against the test set.\n",
    "\n",
    "#### Instructions: Implement `test_logistic_regression` \n",
    "* Given the test data and the weights of your trained model, calculate the accuracy of your logistic regression model. \n",
    "* Use your `predict_tweet()` function to make predictions on each tweet in the test set.\n",
    "* If the prediction is > 0.5, set the model's classification `y_hat` to 1, otherwise set the model's classification `y_hat` to 0.\n",
    "* A prediction is accurate when `y_hat` equals `test_y`.  Sum up all the instances when they are equal and divide by `m`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>Use np.asarray() to convert a list to a numpy array</li>\n",
    "    <li>Use np.squeeze() to make an (m,1) dimensional array into an (m,) array </li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        test_x: a list of tweets\n",
    "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
    "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
    "        theta: weight vector of dimension (3, 1)\n",
    "    Output: \n",
    "        accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # the list for storing predictions\n",
    "    y_hat = []\n",
    "    \n",
    "    for tweet in test_x:\n",
    "        # get the label prediction for the tweet\n",
    "        y_pred = predict_tweet(tweet, freqs, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "            y_hat.append(1.0)\n",
    "            None\n",
    "        else:\n",
    "            # append 0 to the list\n",
    "            y_hat.append(0)\n",
    "\n",
    "    # With the above implementation, y_hat is a list, but test_y is (m,1) array\n",
    "    # convert both to one-dimensional arrays in order to compare them using the '==' operator\n",
    "    y_hat = np.array(y_hat)\n",
    "    test_y = test_y.flatten()\n",
    "    \n",
    "    accuracy = np.mean(y_hat == test_y)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.8980\n"
     ]
    }
   ],
   "source": [
    "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output: \n",
    "```0.9950```  \n",
    "Pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Error Analysis\n",
    "\n",
    "In this part you will see some tweets that your model misclassified. Why do you think the misclassifications happened? Specifically what kind of tweets does your model misclassify?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Predicted Tweet\n",
      "THE TWEET IS: @BBCRadio3 thought it was my ears which were malfunctioning, thank goodness you cleared that one up with an apology :-)\n",
      "THE PROCESSED TWEET IS: ['thought', 'ear', 'malfunct', 'thank', 'good', 'clear', 'one', 'apolog', ':-)']\n",
      "1\t0.46974717\tb'thought ear malfunct thank good clear one apolog :-)'\n",
      "THE TWEET IS: @FindBenNeedham it's my birthday today so for my birthday wish I hope there's good news about Ben soon :-)\n",
      "THE PROCESSED TWEET IS: ['birthday', 'today', 'birthday', 'wish', 'hope', \"there'\", 'good', 'news', 'ben', 'soon', ':-)']\n",
      "1\t0.39879076\tb\"birthday today birthday wish hope there' good news ben soon :-)\"\n",
      "THE TWEET IS: Good morning all :-)\n",
      "\n",
      "It's Friday!!!!!! ó¾°€\n",
      "\n",
      "What are your plans for the day? I am currently playing shops with my... http://t.co/qoKquDWcb5\n",
      "THE PROCESSED TWEET IS: ['good', 'morn', ':-)', 'friday', '\\U000fec00', 'plan', 'day', 'current', 'play', 'shop', '...']\n",
      "1\t0.35379621\tb'good morn :-) friday  plan day current play shop ...'\n",
      "THE TWEET IS: @Gurmeetramrahim #OurDaughtersOurPride dhan dhan satguru tera hi aasra...many congratulations Pita G...Keep them blessed as always :-)\n",
      "THE PROCESSED TWEET IS: ['ourdaughtersourprid', 'dhan', 'dhan', 'satguru', 'tera', 'hi', 'aasra', '...', 'mani', 'congratul', 'pita', 'g', '...', 'keep', 'bless', 'alway', ':-)']\n",
      "1\t0.29208990\tb'ourdaughtersourprid dhan dhan satguru tera hi aasra ... mani congratul pita g ... keep bless alway :-)'\n",
      "THE TWEET IS: @SCOOTERBLUE1962 Thanks yes let's hope so, at work so missing it!!:-)\n",
      "THE PROCESSED TWEET IS: ['thank', 'ye', \"let'\", 'hope', 'work', 'miss', ':-)']\n",
      "1\t0.35432721\tb\"thank ye let' hope work miss :-)\"\n",
      "THE TWEET IS: DAT RP THO. thank you so much you guys for celebrating one month of partnership with me!!! ty @MadMorphTV for the raid! :D\n",
      "THE PROCESSED TWEET IS: ['dat', 'rp', 'tho', 'thank', 'much', 'guy', 'celebr', 'one', 'month', 'partnership', 'ty', 'raid', ':d']\n",
      "1\t0.41146908\tb'dat rp tho thank much guy celebr one month partnership ty raid :d'\n",
      "THE TWEET IS: http://t.co/t2z9ax4qyd - hey, now! Come see us at the @NTCalkeAbbey Summer Fine Food Fair on Sunday, 11am-4pm in the Riding School :)\n",
      "THE PROCESSED TWEET IS: []\n",
      "1\t0.49999991\tb''\n",
      "THE TWEET IS: @jaredNOTsubway @iluvmariah @Bravotv Then that truly is a LATERAL move! Now, we all know the Queen Bee is UPWARD BOUND : ) #MovingOnUp\n",
      "THE PROCESSED TWEET IS: ['truli', 'later', 'move', 'know', 'queen', 'bee', 'upward', 'bound', 'movingonup']\n",
      "1\t0.44626237\tb'truli later move know queen bee upward bound movingonup'\n",
      "THE TWEET IS: @CaballeroSerena you actually need to stop tweeting and driving! :-)))))))\n",
      "THE PROCESSED TWEET IS: ['actual', 'need', 'stop', 'tweet', 'drive', ':-)']\n",
      "1\t0.47662662\tb'actual need stop tweet drive :-)'\n",
      "THE TWEET IS: @matthewcrosby Hope it goes well! :-)\n",
      "THE PROCESSED TWEET IS: ['hope', 'goe', 'well', ':-)']\n",
      "1\t0.49900212\tb'hope goe well :-)'\n",
      "THE TWEET IS: @olemanbob Followed all! :-)\n",
      "THE PROCESSED TWEET IS: ['follow', ':-)']\n",
      "1\t0.46240033\tb'follow :-)'\n",
      "THE TWEET IS: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n",
      "THE PROCESSED TWEET IS: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n",
      "1\t0.23275305\tb'sure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p'\n",
      "THE TWEET IS: @thewhitespike I like them, especially the Klee ones :-)\n",
      "THE PROCESSED TWEET IS: ['like', 'especi', 'klee', 'one', ':-)']\n",
      "1\t0.43140358\tb'like especi klee one :-)'\n",
      "THE TWEET IS: @undeux you look amazing April love the glasses :D\n",
      "THE PROCESSED TWEET IS: ['look', 'amaz', 'april', 'love', 'glass', ':d']\n",
      "1\t0.48581443\tb'look amaz april love glass :d'\n",
      "THE TWEET IS: @Catargiu Yeah, kinda feel like a warm butter in here :D\n",
      "THE PROCESSED TWEET IS: ['yeah', 'kinda', 'feel', 'like', 'warm', 'butter', ':d']\n",
      "1\t0.39728696\tb'yeah kinda feel like warm butter :d'\n",
      "THE TWEET IS: i'm going to sleep. i hope i wake up with a follow from luke hemmings someday :) goodnight fam ily and 5sos a lot ðŸ’Ÿ http://t.co/YX0hTS3lXT\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'go', 'sleep', 'hope', 'wake', 'follow', 'luke', 'hem', 'someday', ':)', 'goodnight', 'fam', 'ili', '5so', 'lot', 'ðŸ’Ÿ']\n",
      "1\t0.41017687\tb\"i'm go sleep hope wake follow luke hem someday :) goodnight fam ili 5so lot \"\n",
      "THE TWEET IS: @Svg_Brad Congrads !!! Better update your About page on the accomplishment !!! :-) Keep it up...\n",
      "THE PROCESSED TWEET IS: ['congrad', 'better', 'updat', 'page', 'accomplish', ':-)', 'keep', '...']\n",
      "1\t0.41052036\tb'congrad better updat page accomplish :-) keep ...'\n",
      "THE TWEET IS: whenever my sister sees me crying she texts me to ask if im okay aw someone cares :-)\n",
      "THE PROCESSED TWEET IS: ['whenev', 'sister', 'see', 'cri', 'text', 'ask', 'im', 'okay', 'aw', 'someon', 'care', ':-)']\n",
      "1\t0.38693428\tb'whenev sister see cri text ask im okay aw someon care :-)'\n",
      "THE TWEET IS: @SisiphoMphoza Can't wait to see you there :-)\n",
      "THE PROCESSED TWEET IS: [\"can't\", 'wait', 'see', ':-)']\n",
      "1\t0.43409871\tb\"can't wait see :-)\"\n",
      "THE TWEET IS: @AndyHerren I know how dumb, did she think of that on her own. But Johnny does rock have u seen his utube video's?  Mad Respect! :D\n",
      "THE PROCESSED TWEET IS: ['know', 'dumb', 'think', 'johnni', 'rock', 'u', 'seen', 'utub', \"video'\", 'mad', 'respect', ':d']\n",
      "1\t0.40589512\tb\"know dumb think johnni rock u seen utub video' mad respect :d\"\n",
      "THE TWEET IS: Hi,i'm definetly so exited ^^ I'm going to New york.:)\n",
      "THE PROCESSED TWEET IS: ['hi', \"i'm\", 'definetli', 'exit', \"i'm\", 'go', 'new', 'york', ':)']\n",
      "1\t0.45038087\tb\"hi i'm definetli exit i'm go new york :)\"\n",
      "THE TWEET IS: @babypuffinator i've typed worse things, it's all good :p\n",
      "THE PROCESSED TWEET IS: [\"i'v\", 'type', 'wors', 'thing', 'good', ':p']\n",
      "1\t0.43809096\tb\"i'v type wors thing good :p\"\n",
      "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots\n",
      "http://t.co/UGQzOx0huu\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.37029692\tb\"i'm play brain dot braindot\"\n",
      "THE TWEET IS: goodnight guys :-) \n",
      "remember tomorrow is a brand new day, a fresh start and another chance\n",
      "THE PROCESSED TWEET IS: ['goodnight', 'guy', ':-)', 'rememb', 'tomorrow', 'brand', 'new', 'day', 'fresh', 'start', 'anoth', 'chanc']\n",
      "1\t0.44678345\tb'goodnight guy :-) rememb tomorrow brand new day fresh start anoth chanc'\n",
      "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.37029692\tb\"i'm play brain dot braindot\"\n",
      "THE TWEET IS: *yawns* good morning everyone *wags tail* how is everyone doing today :D\n",
      "THE PROCESSED TWEET IS: ['yawn', 'good', 'morn', 'everyon', 'wag', 'tail', 'everyon', 'today', ':d']\n",
      "1\t0.47628384\tb'yawn good morn everyon wag tail everyon today :d'\n",
      "THE TWEET IS: Every year in August I get fever :p dunno why ðŸ˜·\n",
      "THE PROCESSED TWEET IS: ['everi', 'year', 'august', 'get', 'fever', ':p', 'dunno', 'ðŸ˜·']\n",
      "1\t0.41446075\tb'everi year august get fever :p dunno '\n",
      "THE TWEET IS: @Clareyh Yeah, it's a classy look :-). I've seen people attached to all sorts of 'life saving' equipment, some in beds,having their fix :-0)\n",
      "THE PROCESSED TWEET IS: ['yeah', 'classi', 'look', ':-)', \"i'v\", 'seen', 'peopl', 'attach', 'sort', 'life', 'save', 'equip', 'bed', 'fix', '0']\n",
      "1\t0.42773841\tb\"yeah classi look :-) i'v seen peopl attach sort life save equip bed fix 0\"\n",
      "THE TWEET IS: Movie 'Key of Life' (Japanese Version) https://t.co/ib4kfpbBu8 interesting storyline! :)\n",
      "THE PROCESSED TWEET IS: ['movi', 'key', 'life', 'japanes', 'version']\n",
      "1\t0.47897592\tb'movi key life japanes version'\n",
      "THE TWEET IS: @Gotzefying Im trying to D/L MH3 english patch for the psp :D\n",
      "THE PROCESSED TWEET IS: ['im', 'tri', 'l', 'mh3', 'english', 'patch', 'psp', ':d']\n",
      "1\t0.46999696\tb'im tri l mh3 english patch psp :d'\n",
      "THE TWEET IS: h_eartshapedbox: First leg of the magictrikband tour is going well! :D #music #band #rock #magictrik #tour â€¦ http://t.co/3SdqjnwDfM\n",
      "THE PROCESSED TWEET IS: ['h_eartshapedbox', 'first', 'leg', 'magictrikband', 'tour', 'go', 'well', ':d', 'music', 'band', 'rock', 'magictrik', 'tour', 'â€¦']\n",
      "1\t0.42819098\tb'h_eartshapedbox first leg magictrikband tour go well :d music band rock magictrik tour '\n",
      "THE TWEET IS: yeah they're giving me subtle hints. also tip #2: don't use it all and the community these last few years. :-) Primâ€™s Algorithm III\n",
      "THE PROCESSED TWEET IS: ['yeah', \"they'r\", 'give', 'subtl', 'hint', 'also', 'tip', '2', 'use', 'commun', 'last', 'year', ':-)', 'prim', 'â€™', 'algorithm', 'iii']\n",
      "1\t0.45059804\tb\"yeah they'r give subtl hint also tip 2 use commun last year :-) prim  algorithm iii\"\n",
      "THE TWEET IS: @JewelStaite Funny, but yes too soon. It's always going to be too soon. :D\n",
      "THE PROCESSED TWEET IS: ['funni', 'ye', 'soon', 'alway', 'go', 'soon', ':d']\n",
      "1\t0.40637064\tb'funni ye soon alway go soon :d'\n",
      "THE TWEET IS: @storpey don't die, you're actually pretty entertaining :p\n",
      "THE PROCESSED TWEET IS: ['die', 'actual', 'pretti', 'entertain', ':p']\n",
      "1\t0.48953708\tb'die actual pretti entertain :p'\n",
      "THE TWEET IS: Morning all...Judith here to answer any District Council related questions today :-)\n",
      "THE PROCESSED TWEET IS: ['morn', '...', 'judith', 'answer', 'district', 'council', 'relat', 'question', 'today', ':-)']\n",
      "1\t0.39191386\tb'morn ... judith answer district council relat question today :-)'\n",
      "THE TWEET IS: @TheAvianFurry Oh dang. That is some zen looking \"outside\" space. Neat :-)\n",
      "THE PROCESSED TWEET IS: ['oh', 'dang', 'zen', 'look', 'outsid', 'space', 'neat', ':-)']\n",
      "1\t0.48329063\tb'oh dang zen look outsid space neat :-)'\n",
      "THE TWEET IS: @dv891798 Learning a new skill takes time to perfect &amp; master. https://t.co/u9YXV5HPjO - Thanks for the favourite :)\n",
      "THE PROCESSED TWEET IS: ['learn', 'new', 'skill', 'take', 'time', 'perfect', 'master']\n",
      "1\t0.42294432\tb'learn new skill take time perfect master'\n",
      "THE TWEET IS: A new report talks about how we burn more calories in the cold, because we work harder to warm up. Feel any better about the weather? :p\n",
      "THE PROCESSED TWEET IS: ['new', 'report', 'talk', 'burn', 'calori', 'cold', 'work', 'harder', 'warm', 'feel', 'better', 'weather', ':p']\n",
      "1\t0.35030695\tb'new report talk burn calori cold work harder warm feel better weather :p'\n",
      "THE TWEET IS: Say something, I'm giving up on you :)\n",
      "And I'm sorry that I couldn't get to you :D\n",
      "THE PROCESSED TWEET IS: ['say', 'someth', \"i'm\", 'give', ':)', \"i'm\", 'sorri', 'get', ':d']\n",
      "1\t0.42083617\tb\"say someth i'm give :) i'm sorri get :d\"\n",
      "THE TWEET IS: @seananmcguire my best friend Carina is one here in San Francisco. Let me know if you want to get I touch. :)\n",
      "THE PROCESSED TWEET IS: ['best', 'friend', 'carina', 'one', 'san', 'francisco', 'let', 'know', 'want', 'get', 'touch', ':)']\n",
      "1\t0.49729109\tb'best friend carina one san francisco let know want get touch :)'\n",
      "THE TWEET IS: @ShutUpBrickLP if only there was uhc in a box on a large scale on one of those network servers :p\n",
      "THE PROCESSED TWEET IS: ['uhc', 'box', 'larg', 'scale', 'one', 'network', 'server', ':p']\n",
      "1\t0.45532160\tb'uhc box larg scale one network server :p'\n",
      "THE TWEET IS: @VincentTong007 Can't wait to be out there again. Just a few weeks now! :D\n",
      "THE PROCESSED TWEET IS: [\"can't\", 'wait', 'week', ':d']\n",
      "1\t0.44954589\tb\"can't wait week :d\"\n",
      "THE TWEET IS: @tbhhowell oh shoot, well i am watching it now :D\n",
      "THE PROCESSED TWEET IS: ['oh', 'shoot', 'well', 'watch', ':d']\n",
      "1\t0.46856327\tb'oh shoot well watch :d'\n",
      "THE TWEET IS: @sonny370 @Arsenal @LFC far from it. Being LFC fan makes me expert in spotting mental weakness and lack consistency :-)\n",
      "THE PROCESSED TWEET IS: ['far', 'lfc', 'fan', 'make', 'expert', 'spot', 'mental', 'weak', 'lack', 'consist', ':-)']\n",
      "1\t0.49758031\tb'far lfc fan make expert spot mental weak lack consist :-)'\n",
      "THE TWEET IS: @llredraven @LinnySmit @erincheshirecat @phycoinsc @paigejiffy @lilginger864 @BlueCat_hikes   Good night! Sweet dreams!  : )  xxoo  â™¡â™¥â™¡\n",
      "THE PROCESSED TWEET IS: ['good', 'night', 'sweet', 'dream', 'xxoo', 'â™¡', 'â™¥', 'â™¡']\n",
      "1\t0.44492053\tb'good night sweet dream xxoo   '\n",
      "THE TWEET IS: @GB_FollowBack I FOLLOW EVERYONE BACK!! #TeamFollowback :-)\n",
      "THE PROCESSED TWEET IS: ['follow', 'everyon', 'back', 'teamfollowback', ':-)']\n",
      "1\t0.41766995\tb'follow everyon back teamfollowback :-)'\n",
      "THE TWEET IS: Amazing pics today on http://t.co/dcifNBjTXA @kellyhallmodel  :D http://t.co/Ja2vPugANE\n",
      "THE PROCESSED TWEET IS: ['amaz', 'pic', 'today']\n",
      "1\t0.45817409\tb'amaz pic today'\n",
      "THE TWEET IS: @javeedna that's a build up for Sunday :p\n",
      "THE PROCESSED TWEET IS: [\"that'\", 'build', 'sunday', ':p']\n",
      "1\t0.48909700\tb\"that' build sunday :p\"\n",
      "THE TWEET IS: @mutleydo @JordanAdams You can get us on Tune In as well as our own app - multiple options! :D\n",
      "THE PROCESSED TWEET IS: ['get', 'us', 'tune', 'well', 'app', 'multipl', 'option', ':d']\n",
      "1\t0.44379631\tb'get us tune well app multipl option :d'\n",
      "THE TWEET IS: @IstanbulPHP nice one :D\n",
      "THE PROCESSED TWEET IS: ['nice', 'one', ':d']\n",
      "1\t0.49737660\tb'nice one :d'\n",
      "THE TWEET IS: @mariammaslouhi If it HAD been two ~17 year olds deeply in love? :-)))\n",
      "THE PROCESSED TWEET IS: ['two', '17', 'year', 'old', 'deepli', 'love', ':-)']\n",
      "1\t0.49705283\tb'two 17 year old deepli love :-)'\n",
      "THE TWEET IS: hah....and a thousand more lies  :D https://t.co/QEil0C0auo\n",
      "THE PROCESSED TWEET IS: ['hah', '...', 'thousand', 'lie', ':d']\n",
      "1\t0.42919096\tb'hah ... thousand lie :d'\n",
      "THE TWEET IS: In #Fallout4 we get to see the Glowing Sea. Again. \n",
      "\n",
      "Technically did in Fallout 3. I just played again to see :D http://t.co/zRP17qI0qT\n",
      "THE PROCESSED TWEET IS: ['fallout', '4', 'get', 'see', 'glow', 'sea', 'technic', 'fallout', '3', 'play', 'see', ':d']\n",
      "1\t0.37140012\tb'fallout 4 get see glow sea technic fallout 3 play see :d'\n",
      "THE TWEET IS: @pmjeepers I'm a friend of your cousin Karen Gunderson. Just watched Europa Report -- thoroughly impressed! Wanted to say, great script!:-)\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'friend', 'cousin', 'karen', 'gunderson', 'watch', 'europa', 'report', 'thoroughli', 'impress', 'want', 'say', 'great', 'script', ':-)']\n",
      "1\t0.30871717\tb\"i'm friend cousin karen gunderson watch europa report thoroughli impress want say great script :-)\"\n",
      "THE TWEET IS: @LusciousLyndee1 hahaha...and thus...I sneak away to log on to #niteflirt :D\n",
      "THE PROCESSED TWEET IS: ['hahaha', '...', 'thu', '...', 'sneak', 'away', 'log', 'niteflirt', ':d']\n",
      "1\t0.30843483\tb'hahaha ... thu ... sneak away log niteflirt :d'\n",
      "THE TWEET IS: @wontanim yep we're all trash af   im from indonesia hbu? :-))\n",
      "THE PROCESSED TWEET IS: ['yep', \"we'r\", 'trash', 'af', 'im', 'indonesia', 'hbu', ':-)']\n",
      "1\t0.48799422\tb\"yep we'r trash af im indonesia hbu :-)\"\n",
      "THE TWEET IS: @ISupportTony You're obviously getting better at your tweets :-)\n",
      "THE PROCESSED TWEET IS: ['obvious', 'get', 'better', 'tweet', ':-)']\n",
      "1\t0.45794234\tb'obvious get better tweet :-)'\n",
      "THE TWEET IS: Here's a reminder. As if we needed one :-) http://t.co/IWLQK3XB3H\n",
      "THE PROCESSED TWEET IS: [\"here'\", 'remind', 'need', 'one', ':-)']\n",
      "1\t0.46811174\tb\"here' remind need one :-)\"\n",
      "THE TWEET IS: Harry and niall and -94 (when harry was born) ik it's stupid and i wanna change it :D https://t.co/gHAt8ZDAfF\n",
      "THE PROCESSED TWEET IS: ['harri', 'niall', '94', 'harri', 'born', 'ik', 'stupid', 'wanna', 'chang', ':d']\n",
      "1\t0.48943261\tb'harri niall 94 harri born ik stupid wanna chang :d'\n",
      "THE TWEET IS: @miabellasesso http://t.co/FtI5vLQJks @SBNation and a few select others.. will get to you :)\n",
      "THE PROCESSED TWEET IS: []\n",
      "1\t0.49999991\tb''\n",
      "THE TWEET IS: @dukeofdelhi yes please would brighten up my night shift #nomnomnom :D #chocolate #DukeFreebieFriday to  xx\n",
      "THE PROCESSED TWEET IS: ['ye', 'pleas', 'would', 'brighten', 'night', 'shift', 'nomnomnom', ':d', 'chocol', 'dukefreebiefriday', 'xx']\n",
      "1\t0.38517926\tb'ye pleas would brighten night shift nomnomnom :d chocol dukefreebiefriday xx'\n",
      "THE TWEET IS: @NiaFHenry Hi! I see u like FourFiveSeconds and think u might like \"Deaf Ears\" https://t.co/FsS7lzF8HQ .Plz let me know what u think :)\n",
      "THE PROCESSED TWEET IS: ['hi', 'see', 'u', 'like', 'fourfivesecond', 'think', 'u', 'might', 'like', 'deaf', 'ear']\n",
      "1\t0.20967646\tb'hi see u like fourfivesecond think u might like deaf ear'\n",
      "THE TWEET IS: Happy Birthday Mitch :-) i wish you all the best have a good day http://t.co/4LHrrWv42e\n",
      "THE PROCESSED TWEET IS: ['happi', 'birthday', 'mitch', ':-)', 'wish', 'best', 'good', 'day']\n",
      "1\t0.46418531\tb'happi birthday mitch :-) wish best good day'\n",
      "THE TWEET IS: @SpazzyTsukihara lol ok i can watch ya for a bit :p\n",
      "THE PROCESSED TWEET IS: ['lol', 'ok', 'watch', 'ya', 'bit', ':p']\n",
      "1\t0.45697808\tb'lol ok watch ya bit :p'\n",
      "THE TWEET IS: My ghost #bae :D #love #wuppertal #TagsForLikesApp #instagood #me #smile #follow #cute #photoofthedayâ€¦ https://t.co/jppbF7UIK3\n",
      "THE PROCESSED TWEET IS: ['ghost', 'bae', ':d', 'love', 'wuppert', 'tagsforlikesapp', 'instagood', 'smile', 'follow', 'cute', 'photooftheday', 'â€¦']\n",
      "1\t0.40457372\tb'ghost bae :d love wuppert tagsforlikesapp instagood smile follow cute photooftheday '\n",
      "THE TWEET IS: Morning! How are u #today?  What have u got planned? How lazy am I? I'm still in bed! Toast &amp; fresh coffee 2 :). Have a great #FridayFunDay\n",
      "THE PROCESSED TWEET IS: ['morn', 'u', 'today', 'u', 'got', 'plan', 'lazi', \"i'm\", 'still', 'bed', 'toast', 'fresh', 'coffe', '2', ':)', 'great', 'fridayfunday']\n",
      "1\t0.39212889\tb\"morn u today u got plan lazi i'm still bed toast fresh coffe 2 :) great fridayfunday\"\n",
      "THE TWEET IS: can I just meet harry that's all I need in life :-)\n",
      "THE PROCESSED TWEET IS: ['meet', 'harri', \"that'\", 'need', 'life', ':-)']\n",
      "1\t0.47508588\tb\"meet harri that' need life :-)\"\n",
      "THE TWEET IS: One more sleep til the wedding :-)\n",
      "THE PROCESSED TWEET IS: ['one', 'sleep', 'til', 'wed', ':-)']\n",
      "1\t0.46781498\tb'one sleep til wed :-)'\n",
      "THE TWEET IS: @GBattered @JimmysFarmHQ enjoy, hope weather holds for you guys :-)\n",
      "THE PROCESSED TWEET IS: ['enjoy', 'hope', 'weather', 'hold', 'guy', ':-)']\n",
      "1\t0.48815866\tb'enjoy hope weather hold guy :-)'\n",
      "THE TWEET IS: @TheVampsCon im thankful to have someone like you in my life to inspire me to be better everyday. i love you, mind following me? :)\n",
      "THE PROCESSED TWEET IS: ['im', 'thank', 'someon', 'like', 'life', 'inspir', 'better', 'everyday', 'love', 'mind', 'follow', ':)']\n",
      "1\t0.49253501\tb'im thank someon like life inspir better everyday love mind follow :)'\n",
      "THE TWEET IS: Crazy girlfriends be like :-)(-: Jesus Christ. http://t.co/RTWjc7e1lM\n",
      "THE PROCESSED TWEET IS: ['crazi', 'girlfriend', 'like', ':-)', '(-:', 'jesu', 'christ']\n",
      "1\t0.47778969\tb'crazi girlfriend like :-) (-: jesu christ'\n",
      "THE TWEET IS: @grafikmag @editionsdulivre I a kid inside!!! I want one!! :-)\n",
      "THE PROCESSED TWEET IS: ['kid', 'insid', 'want', 'one', ':-)']\n",
      "1\t0.40942853\tb'kid insid want one :-)'\n",
      "THE TWEET IS: do u use any app to listen to music? if yes, what app? :-) â€” idownloader http://t.co/L4o5J39UEf\n",
      "THE PROCESSED TWEET IS: ['u', 'use', 'app', 'listen', 'music', 'ye', 'app', ':-)', 'â€”', 'idownload']\n",
      "1\t0.43939927\tb'u use app listen music ye app :-)  idownload'\n",
      "THE TWEET IS: @ShortgamerUHC I get 25ish then more if I snowball :p\n",
      "THE PROCESSED TWEET IS: ['get', '25ish', 'snowbal', ':p']\n",
      "1\t0.43695653\tb'get 25ish snowbal :p'\n",
      "THE TWEET IS: nd its going to expire next year. dat is mtn 6gb for u :D , You really like it?\n",
      "THE PROCESSED TWEET IS: ['nd', 'go', 'expir', 'next', 'year', 'dat', 'mtn', '6gb', 'u', ':d', 'realli', 'like']\n",
      "1\t0.27882964\tb'nd go expir next year dat mtn 6gb u :d realli like'\n",
      "THE TWEET IS: I wanna go back to the time were everything is still fine. :-)\n",
      "THE PROCESSED TWEET IS: ['wanna', 'go', 'back', 'time', 'everyth', 'still', 'fine', ':-)']\n",
      "1\t0.30186712\tb'wanna go back time everyth still fine :-)'\n",
      "THE TWEET IS: @Memz_Dogi i'm joining right now :D\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'join', 'right', ':d']\n",
      "1\t0.41473565\tb\"i'm join right :d\"\n",
      "THE TWEET IS: @melaniemorris Hi Melanie :-) We do in fact, they're really used in cases where normal WiFi could be an issue as you mentioned. You can ....\n",
      "THE PROCESSED TWEET IS: ['hi', 'melani', ':-)', 'fact', \"they'r\", 'realli', 'use', 'case', 'normal', 'wifi', 'could', 'issu', 'mention', '...']\n",
      "1\t0.34468131\tb\"hi melani :-) fact they'r realli use case normal wifi could issu mention ...\"\n",
      "THE TWEET IS: @wildrunnerza @ctmarathon @runnersworldza One of those \"ok i'll run for the photo' moments :D\n",
      "THE PROCESSED TWEET IS: ['one', 'ok', \"i'll\", 'run', 'photo', 'moment', ':d']\n",
      "1\t0.46563633\tb\"one ok i'll run photo moment :d\"\n",
      "THE TWEET IS: I slept less that 7 hours last night, preparing myself for possible naps :p\n",
      "THE PROCESSED TWEET IS: ['slept', 'less', '7', 'hour', 'last', 'night', 'prepar', 'possibl', 'nap', ':p']\n",
      "1\t0.45610627\tb'slept less 7 hour last night prepar possibl nap :p'\n",
      "THE TWEET IS: @ochoaofficiaI idk :p she follows meðŸ˜ŽðŸ’ðŸ»\n",
      "THE PROCESSED TWEET IS: ['idk', ':p', 'follow', 'ðŸ˜Ž', 'ðŸ’ðŸ»']\n",
      "1\t0.41254409\tb'idk :p follow  '\n",
      "THE TWEET IS: I feel like having a relapse :-)\n",
      "THE PROCESSED TWEET IS: ['feel', 'like', 'relaps', ':-)']\n",
      "1\t0.41996458\tb'feel like relaps :-)'\n",
      "THE TWEET IS: Girl : nice wallet.\n",
      "Boy : Prada hai..\n",
      "Girl: you're so rich then..\n",
      "Boy: stupid, I mean bhai ka hai. :p\n",
      "#prada #PunjabisWillGetIt\n",
      "THE PROCESSED TWEET IS: ['girl', 'nice', 'wallet', 'boy', 'prada', 'hai', '..', 'girl', 'rich', '..', 'boy', 'stupid', 'mean', 'bhai', 'ka', 'hai', ':p', 'prada', 'punjabiswillgetit']\n",
      "1\t0.39329232\tb'girl nice wallet boy prada hai .. girl rich .. boy stupid mean bhai ka hai :p prada punjabiswillgetit'\n",
      "THE TWEET IS: Only my bad would remind me to exercise at 1:12 in the am :-). \n",
      " I miss her. She needs to come back. Now.\n",
      "THE PROCESSED TWEET IS: ['bad', 'would', 'remind', 'exercis', '1:12', ':-)', 'miss', 'need', 'come', 'back']\n",
      "1\t0.29513885\tb'bad would remind exercis 1:12 :-) miss need come back'\n",
      "THE TWEET IS: @Junaidogic kyunke Aitchison hai :p look at the responses to my original tweet, you'll know why my brother does this\n",
      "THE PROCESSED TWEET IS: ['kyunk', 'aitchison', 'hai', ':p', 'look', 'respons', 'origin', 'tweet', 'know', 'brother']\n",
      "1\t0.42063868\tb'kyunk aitchison hai :p look respons origin tweet know brother'\n",
      "THE TWEET IS: @Bixbersboca good morning to you :D lol its really fuckin dark and it's gonna rain so hard in a couple of minutes\n",
      "THE PROCESSED TWEET IS: ['good', 'morn', ':d', 'lol', 'realli', 'fuckin', 'dark', 'gonna', 'rain', 'hard', 'coupl', 'minut']\n",
      "1\t0.41108883\tb'good morn :d lol realli fuckin dark gonna rain hard coupl minut'\n",
      "THE TWEET IS: @AsianMeerkat @johncrossmirror far from it. Being LFC fan makes me expert in spotting mental weakness and lack consistency :-)\n",
      "THE PROCESSED TWEET IS: ['far', 'lfc', 'fan', 'make', 'expert', 'spot', 'mental', 'weak', 'lack', 'consist', ':-)']\n",
      "1\t0.49758031\tb'far lfc fan make expert spot mental weak lack consist :-)'\n",
      "THE TWEET IS: i'm in amsterdam guys wooo :D\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'amsterdam', 'guy', 'wooo', ':d']\n",
      "1\t0.41332194\tb\"i'm amsterdam guy wooo :d\"\n",
      "THE TWEET IS: You always be part of me, I am part of you and defenitely...â™¬ @MOHDBINTANG :p\n",
      "THE PROCESSED TWEET IS: ['alway', 'part', 'part', 'defenit', '...', 'â™¬', ':p']\n",
      "1\t0.36969875\tb'alway part part defenit ...  :p'\n",
      "THE TWEET IS: @martymccarthy1 @ABCRural A great incentive to get kids to eat their Fruit &amp; Veges :-)\n",
      "THE PROCESSED TWEET IS: ['great', 'incent', 'get', 'kid', 'eat', 'fruit', 'vege', ':-)']\n",
      "1\t0.46632339\tb'great incent get kid eat fruit vege :-)'\n",
      "THE TWEET IS: I guess sleep was just not in my list of things to do today :-)\n",
      "THE PROCESSED TWEET IS: ['guess', 'sleep', 'list', 'thing', 'today', ':-)']\n",
      "1\t0.46298176\tb'guess sleep list thing today :-)'\n",
      "THE TWEET IS: @zaynmalik Zayn please follow me, would mean the world! It's my birthday :D I love you so much, your amazing&lt;3\n",
      "THE PROCESSED TWEET IS: ['zayn', 'pleas', 'follow', 'would', 'mean', 'world', 'birthday', ':d', 'love', 'much', 'amaz', '<3']\n",
      "1\t0.24318125\tb'zayn pleas follow would mean world birthday :d love much amaz <3'\n",
      "THE TWEET IS: @PoemPorns hah....and a thousand more lies  :D\n",
      "THE PROCESSED TWEET IS: ['hah', '...', 'thousand', 'lie', ':d']\n",
      "1\t0.42919096\tb'hah ... thousand lie :d'\n",
      "THE TWEET IS: @flurishing @blxcknicotine wow,looking good isabella! Makes me wanna start working out back :D\n",
      "THE PROCESSED TWEET IS: ['wow', 'look', 'good', 'isabella', 'make', 'wanna', 'start', 'work', 'back', ':d']\n",
      "1\t0.33420600\tb'wow look good isabella make wanna start work back :d'\n",
      "THE TWEET IS: going to my room now bc i have 3% :-)\n",
      "THE PROCESSED TWEET IS: ['go', 'room', 'bc', '3', ':-)']\n",
      "1\t0.44195190\tb'go room bc 3 :-)'\n",
      "THE TWEET IS: At least there's one cool thing :-))))\n",
      "THE PROCESSED TWEET IS: ['least', \"there'\", 'one', 'cool', 'thing', ':-)']\n",
      "1\t0.47673161\tb\"least there' one cool thing :-)\"\n",
      "THE TWEET IS: @starksmurdock AHH THANK U :D\n",
      "THE PROCESSED TWEET IS: ['ahh', 'thank', 'u', ':d']\n",
      "1\t0.48587158\tb'ahh thank u :d'\n",
      "THE TWEET IS: niall followed a fan :) and i'm still here without his follow ðŸ‘\n",
      "THE PROCESSED TWEET IS: ['niall', 'follow', 'fan', ':)', \"i'm\", 'still', 'without', 'follow', 'ðŸ‘']\n",
      "1\t0.41124572\tb\"niall follow fan :) i'm still without follow \"\n",
      "THE TWEET IS: @The_Sleigher among my all time fav tweets :D\n",
      "THE PROCESSED TWEET IS: ['among', 'time', 'fav', 'tweet', ':d']\n",
      "1\t0.48761772\tb'among time fav tweet :d'\n",
      "THE TWEET IS: @KristyArnett Your thinking to hard in bed! :p\n",
      "THE PROCESSED TWEET IS: ['think', 'hard', 'bed', ':p']\n",
      "1\t0.46508608\tb'think hard bed :p'\n",
      "THE TWEET IS: @CG_Rated did u mean to hide the fots? :p\n",
      "THE PROCESSED TWEET IS: ['u', 'mean', 'hide', 'fot', ':p']\n",
      "1\t0.43048303\tb'u mean hide fot :p'\n",
      "THE TWEET IS: Ok good night I wish troye wasn't ugly and I met him today:)():)!:!; but ok today was fun I'm excited for tmrw!!\n",
      "THE PROCESSED TWEET IS: ['ok', 'good', 'night', 'wish', 'troy', 'ugli', 'met', 'today', ':)', '):', 'ok', 'today', 'fun', \"i'm\", 'excit', 'tmrw']\n",
      "1\t0.49305288\tb\"ok good night wish troy ugli met today :) ): ok today fun i'm excit tmrw\"\n",
      "THE TWEET IS: @nakamuramartin @DamienMcFerran @Kosmikat That makes two of us then! :D\n",
      "THE PROCESSED TWEET IS: ['make', 'two', 'us', ':d']\n",
      "1\t0.49783664\tb'make two us :d'\n",
      "THE TWEET IS: @greatestcookie It hurts having to read about people's holidays when being at work :D\n",
      "THE PROCESSED TWEET IS: ['hurt', 'read', \"people'\", 'holiday', 'work', ':d']\n",
      "1\t0.47872532\tb\"hurt read people' holiday work :d\"\n",
      "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/R2JBO8iNww http://t.co/ow5BBwdEMY\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.37029692\tb\"i'm play brain dot braindot\"\n",
      "THE TWEET IS: https://t.co/gBIMDzQBY5 Must watch :D #BajrangiBhaijaanHighestWeek1\n",
      "THE PROCESSED TWEET IS: []\n",
      "1\t0.49999991\tb''\n",
      "THE TWEET IS: @KimKardashian @KendallJenner @KylieJenner @khloekardashian @kourtneykardash Cool..... congrats Kylie!!  U all look so nice    :-)\n",
      "THE PROCESSED TWEET IS: ['cool', '...', 'congrat', 'kyli', 'u', 'look', 'nice', ':-)']\n",
      "1\t0.34900082\tb'cool ... congrat kyli u look nice :-)'\n",
      "THE TWEET IS: @CathsStrawberry I thought your work was  seasonal, you will have really busy days. Ok so deal for weekends and in your toilet breaks :p\n",
      "THE PROCESSED TWEET IS: ['thought', 'work', 'season', 'realli', 'busi', 'day', 'ok', 'deal', 'weekend', 'toilet', 'break', ':p']\n",
      "1\t0.34856618\tb'thought work season realli busi day ok deal weekend toilet break :p'\n",
      "THE TWEET IS: @justinbieber YOU ARE DADDY AF... :-)\n",
      "THE PROCESSED TWEET IS: ['daddi', 'af', '...', ':-)']\n",
      "1\t0.43043870\tb'daddi af ... :-)'\n",
      "THE TWEET IS: When ur skin thinks ur still 16 &amp; decides to break out :-) cool\n",
      "THE PROCESSED TWEET IS: ['ur', 'skin', 'think', 'ur', 'still', '16', 'decid', 'break', ':-)', 'cool']\n",
      "1\t0.45985042\tb'ur skin think ur still 16 decid break :-) cool'\n",
      "THE TWEET IS: @OdellSchwarzeJG How?Easy.Get up at 5:30 am, go to work, come home bout 6, take care of home and family therein. That's how. You'll see. :-)\n",
      "THE PROCESSED TWEET IS: ['easy.get', '5:30', 'go', 'work', 'come', 'home', 'bout', '6', 'take', 'care', 'home', 'famili', 'therein', \"that'\", 'see', ':-)']\n",
      "1\t0.28753590\tb\"easy.get 5:30 go work come home bout 6 take care home famili therein that' see :-)\"\n",
      "THE TWEET IS: @DominiquePirrie @unlatches @ShinonSai Dominique I'm your biggest fan like oh my I'm from England too can I get a fan sign :)\n",
      "THE PROCESSED TWEET IS: ['dominiqu', \"i'm\", 'biggest', 'fan', 'like', 'oh', \"i'm\", 'england', 'get', 'fan', 'sign', ':)']\n",
      "1\t0.34681755\tb\"dominiqu i'm biggest fan like oh i'm england get fan sign :)\"\n",
      "THE TWEET IS: @bridgetminamore I voted for #brainchild 3 times, please may I have a poem? :D\n",
      "THE PROCESSED TWEET IS: ['vote', 'brainchild', '3', 'time', 'pleas', 'may', 'poem', ':d']\n",
      "1\t0.36904606\tb'vote brainchild 3 time pleas may poem :d'\n",
      "THE TWEET IS: Sketchbook art by love4wilde Drawing of hair I did turned out pretty cool :D #art #hair #colors #colorpencils #crayâ€¦ http://t.co/tn1yicz40N\n",
      "THE PROCESSED TWEET IS: ['sketchbook', 'art', 'love', '4wild', 'draw', 'hair', 'turn', 'pretti', 'cool', ':d', 'art', 'hair', 'color', 'colorpencil', 'cray', 'â€¦']\n",
      "1\t0.48716501\tb'sketchbook art love 4wild draw hair turn pretti cool :d art hair color colorpencil cray '\n",
      "THE TWEET IS: Fell asleep at like 6:30 and now can't fall asleep and I have to be up in two hours :-)\n",
      "THE PROCESSED TWEET IS: ['fell', 'asleep', 'like', '6:30', \"can't\", 'fall', 'asleep', 'two', 'hour', ':-)']\n",
      "1\t0.37253175\tb\"fell asleep like 6:30 can't fall asleep two hour :-)\"\n",
      "THE TWEET IS: Goning to make thos a positive day :) you're an adult and i can't keep on acting like your mom..\n",
      "THE PROCESSED TWEET IS: ['gone', 'make', 'tho', 'posit', 'day', ':)', 'adult', \"can't\", 'keep', 'act', 'like', 'mom', '..']\n",
      "1\t0.48700476\tb\"gone make tho posit day :) adult can't keep act like mom ..\"\n",
      "THE TWEET IS: @lindseyasuer Hi! I see u like FourFiveSeconds and think u might like \"Deaf Ears\" https://t.co/nO9B1b1vtN .Plz let me know what u think :)\n",
      "THE PROCESSED TWEET IS: ['hi', 'see', 'u', 'like', 'fourfivesecond', 'think', 'u', 'might', 'like', 'deaf', 'ear']\n",
      "1\t0.20967646\tb'hi see u like fourfivesecond think u might like deaf ear'\n",
      "THE TWEET IS: First leg of the @magictrikband tour is going well! :D #music #band #rock #magictrik #tour https://t.co/CQHqWfa7ft\n",
      "THE PROCESSED TWEET IS: ['first', 'leg', 'tour', 'go', 'well', ':d', 'music', 'band', 'rock', 'magictrik', 'tour']\n",
      "1\t0.43202691\tb'first leg tour go well :d music band rock magictrik tour'\n",
      "THE TWEET IS: @sakshij020 @shabnam_903 okk den call abp n spread it on allover d India n abroad as well :p\n",
      "THE PROCESSED TWEET IS: ['okk', 'den', 'call', 'abp', 'n', 'spread', 'allov', 'india', 'n', 'abroad', 'well', ':p']\n",
      "1\t0.46887031\tb'okk den call abp n spread allov india n abroad well :p'\n",
      "THE TWEET IS: @JulianGazzia Hi :-) If you're looking for tourist info get our application ZonzoFox clicking this link http://t.co/Y8yTe8E9wg. Bye ;-)\n",
      "THE PROCESSED TWEET IS: ['hi', ':-)', 'look', 'tourist', 'info', 'get', 'applic', 'zonzofox', 'click', 'link']\n",
      "1\t0.44909545\tb'hi :-) look tourist info get applic zonzofox click link'\n",
      "THE TWEET IS: lemme cover u in lipstick n cran vodka :-)\n",
      "THE PROCESSED TWEET IS: ['lemm', 'cover', 'u', 'lipstick', 'n', 'cran', 'vodka', ':-)']\n",
      "1\t0.48279830\tb'lemm cover u lipstick n cran vodka :-)'\n",
      "THE TWEET IS: @emily_etc I always walk past this place! May have to go in and try them for myself now ! :D\n",
      "THE PROCESSED TWEET IS: ['alway', 'walk', 'past', 'place', 'may', 'go', 'tri', ':d']\n",
      "1\t0.41404678\tb'alway walk past place may go tri :d'\n",
      "THE TWEET IS: Yo Southpaw was a GREAT movie someone better be getting an award for it :D\n",
      "THE PROCESSED TWEET IS: ['yo', 'southpaw', 'great', 'movi', 'someon', 'better', 'get', 'award', ':d']\n",
      "1\t0.44446051\tb'yo southpaw great movi someon better get award :d'\n",
      "THE TWEET IS: Last classes this morning before two week break! :-)\n",
      "THE PROCESSED TWEET IS: ['last', 'class', 'morn', 'two', 'week', 'break', ':-)']\n",
      "1\t0.49916206\tb'last class morn two week break :-)'\n",
      "THE TWEET IS: @babypuffinator it does, you could have misread worse things :p\n",
      "THE PROCESSED TWEET IS: ['could', 'misread', 'wors', 'thing', ':p']\n",
      "1\t0.46742156\tb'could misread wors thing :p'\n",
      "THE TWEET IS: @lazariWilliams Hey, You like FNaF? Check out our Youtube Channel! https://t.co/sc9kDhaviX :) via http://t.co/J3sxzzg7cU\n",
      "THE PROCESSED TWEET IS: ['hey', 'like', 'fnaf', 'check', 'youtub', 'channel']\n",
      "1\t0.41759646\tb'hey like fnaf check youtub channel'\n",
      "THE TWEET IS: Yup, happen everywhere when people cant debate they come to name calling :-)  https://t.co/dRiMWpj7ON\n",
      "THE PROCESSED TWEET IS: ['yup', 'happen', 'everywher', 'peopl', 'cant', 'debat', 'come', 'name', 'call', ':-)']\n",
      "1\t0.44249011\tb'yup happen everywher peopl cant debat come name call :-)'\n",
      "THE TWEET IS: @Mathpro314 Hey, wanna check out our YTB Channel? We post Gameplays &amp; Tutorials! https://t.co/sc9kDhaviX :) via http://t.co/J3sxzzg7cU\n",
      "THE PROCESSED TWEET IS: ['hey', 'wanna', 'check', 'ytb', 'channel', 'post', 'gameplay', 'tutori']\n",
      "1\t0.45154292\tb'hey wanna check ytb channel post gameplay tutori'\n",
      "THE TWEET IS: @MangleTheLover Hey, You like FNaF? Check out our Youtube Channel! https://t.co/sc9kDhaviX :) via http://t.co/J3sxzzg7cU\n",
      "THE PROCESSED TWEET IS: ['hey', 'like', 'fnaf', 'check', 'youtub', 'channel']\n",
      "1\t0.41759646\tb'hey like fnaf check youtub channel'\n",
      "THE TWEET IS: I WANT to create the FIRST #Bboying #Cardgame with #pixelart #gamedesign :D!!!! What do you think ?? #indiedev #pixel_dailies #gamedev\n",
      "THE PROCESSED TWEET IS: ['want', 'creat', 'first', 'bboy', 'cardgam', 'pixelart', 'gamedesign', ':d', 'think', 'indiedev', 'pixel_daili', 'gamedev']\n",
      "1\t0.42981351\tb'want creat first bboy cardgam pixelart gamedesign :d think indiedev pixel_daili gamedev'\n",
      "THE TWEET IS: @melfoster666 That's not true.\n",
      "I can quit whenever I want to.\n",
      ":D\n",
      "THE PROCESSED TWEET IS: [\"that'\", 'true', 'quit', 'whenev', 'want', ':d']\n",
      "1\t0.43468409\tb\"that' true quit whenev want :d\"\n",
      "THE TWEET IS: If u like uta read the manga :-))) you'll love him even more :-))) haha yeah\n",
      "THE PROCESSED TWEET IS: ['u', 'like', 'uta', 'read', 'manga', ':-)', 'love', 'even', ':-)', 'haha', 'yeah']\n",
      "1\t0.39233296\tb'u like uta read manga :-) love even :-) haha yeah'\n",
      "THE TWEET IS: Those who move forward with a happy spirit will find that things always work out \\:)/\n",
      "THE PROCESSED TWEET IS: ['move', 'forward', 'happi', 'spirit', 'find', 'thing', 'alway', 'work', '\\\\:']\n",
      "1\t0.40421997\tb'move forward happi spirit find thing alway work \\\\:'\n",
      "THE TWEET IS: @pop_ruth you miss this! :-) http://t.co/upXtepl57y\n",
      "THE PROCESSED TWEET IS: ['miss', ':-)']\n",
      "1\t0.43652155\tb'miss :-)'\n",
      "THE TWEET IS: @ElleDonnellyx @Beverleyknight @mattcardle lovely pics, @MemphisMusical a fab show :-) x\n",
      "THE PROCESSED TWEET IS: ['love', 'pic', 'fab', 'show', ':-)', 'x']\n",
      "1\t0.49716899\tb'love pic fab show :-) x'\n",
      "THE TWEET IS: @DeMoorSophie Hii, can you follow me, please? I'd like ask you one thing in dm :)ðŸ’ž\n",
      "THE PROCESSED TWEET IS: ['hii', 'follow', 'pleas', \"i'd\", 'like', 'ask', 'one', 'thing', 'dm', ':)', 'ðŸ’ž']\n",
      "1\t0.41507191\tb\"hii follow pleas i'd like ask one thing dm :) \"\n",
      "THE TWEET IS: @vadervanodin im wearing mine when I dj next fri :-)\n",
      "THE PROCESSED TWEET IS: ['im', 'wear', 'mine', 'dj', 'next', 'fri', ':-)']\n",
      "1\t0.48195586\tb'im wear mine dj next fri :-)'\n",
      "THE TWEET IS: I'm that person that has to workout and eat healthy because the minute I don't I gain weight :-)\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'person', 'workout', 'eat', 'healthi', 'minut', 'gain', 'weight', ':-)']\n",
      "1\t0.41612948\tb\"i'm person workout eat healthi minut gain weight :-)\"\n",
      "THE TWEET IS: Singer Dusty in TUNISIA &lt;3 Music for TUNISIA &lt;3 it was wonderful, very nice people :-) &lt;3\n",
      "\n",
      "YOUTUBE:... http://t.co/859XGmZ1W9\n",
      "THE PROCESSED TWEET IS: ['singer', 'dusti', 'tunisia', '<3', 'music', 'tunisia', '<3', 'wonder', 'nice', 'peopl', ':-)', '<3', 'youtub', '...']\n",
      "1\t0.40909253\tb'singer dusti tunisia <3 music tunisia <3 wonder nice peopl :-) <3 youtub ...'\n",
      "THE TWEET IS: @NotThatBobJames Hahaha Go Doug! :-)\n",
      "THE PROCESSED TWEET IS: ['hahaha', 'go', 'doug', ':-)']\n",
      "1\t0.47055812\tb'hahaha go doug :-)'\n",
      "THE TWEET IS: That also means, imma go back to being more twitter active :D\n",
      "Cause I know everyone missed me ;) xD\n",
      "THE PROCESSED TWEET IS: ['also', 'mean', 'imma', 'go', 'back', 'twitter', 'activ', ':d', 'caus', 'know', 'everyon', 'miss', ';)', 'xd']\n",
      "1\t0.25135577\tb'also mean imma go back twitter activ :d caus know everyon miss ;) xd'\n",
      "THE TWEET IS: @awad_gina @phonicfm @WomenAwards Oh Gina, you have been busy :-) Can't wait to see you and hear all xxx #soproud\n",
      "THE PROCESSED TWEET IS: ['oh', 'gina', 'busi', ':-)', \"can't\", 'wait', 'see', 'hear', 'xxx', 'soproud']\n",
      "1\t0.37981082\tb\"oh gina busi :-) can't wait see hear xxx soproud\"\n",
      "THE TWEET IS: @TheTwoHalvesAle Good luck...another potential favourite watering hole :-)\n",
      "THE PROCESSED TWEET IS: ['good', 'luck', '...', 'anoth', 'potenti', 'favourit', 'water', 'hole', ':-)']\n",
      "1\t0.40100696\tb'good luck ... anoth potenti favourit water hole :-)'\n",
      "THE TWEET IS: who wants to ft me and Arianna :-)\n",
      "THE PROCESSED TWEET IS: ['want', 'ft', 'arianna', ':-)']\n",
      "1\t0.46813777\tb'want ft arianna :-)'\n",
      "THE TWEET IS: @Daniilarkin1 Have fun Danielle! Hope it goes well :-)\n",
      "THE PROCESSED TWEET IS: ['fun', 'daniel', 'hope', 'goe', 'well', ':-)']\n",
      "1\t0.49308577\tb'fun daniel hope goe well :-)'\n",
      "THE TWEET IS: @amyewest Thanks! I hope you've got a good book to keep you company. :-)\n",
      "THE PROCESSED TWEET IS: ['thank', 'hope', 'got', 'good', 'book', 'keep', 'compani', ':-)']\n",
      "1\t0.44182127\tb'thank hope got good book keep compani :-)'\n",
      "THE TWEET IS: @tangerinebean Has A got out of bed yet? :-)\n",
      "THE PROCESSED TWEET IS: ['got', 'bed', 'yet', ':-)']\n",
      "1\t0.49617832\tb'got bed yet :-)'\n",
      "THE TWEET IS: @pottorty awwww! Sige next time u know na punta kayo dun, imma make sure na we'll go din! :-)\n",
      "THE PROCESSED TWEET IS: ['awww', 'sige', 'next', 'time', 'u', 'know', 'na', 'punta', 'kayo', 'dun', 'imma', 'make', 'sure', 'na', \"we'll\", 'go', 'din', ':-)']\n",
      "1\t0.25330505\tb\"awww sige next time u know na punta kayo dun imma make sure na we'll go din :-)\"\n",
      "THE TWEET IS: ...because it's Friday :D (y) http://t.co/MD55NIzEnQ\n",
      "THE PROCESSED TWEET IS: ['...', 'friday', ':d']\n",
      "1\t0.43558245\tb'... friday :d'\n",
      "THE TWEET IS: @vickybeeching congratulations, really looking forward to the book and some good Sunday morning viewing. That's an awesome teapot BTW :-) x\n",
      "THE PROCESSED TWEET IS: ['congratul', 'realli', 'look', 'forward', 'book', 'good', 'sunday', 'morn', 'view', \"that'\", 'awesom', 'teapot', 'btw', ':-)', 'x']\n",
      "1\t0.41131621\tb\"congratul realli look forward book good sunday morn view that' awesom teapot btw :-) x\"\n",
      "THE TWEET IS: @PXC_Macavity In case you didn't.. it's on my Facebook wall. :p\n",
      "THE PROCESSED TWEET IS: ['case', '..', 'facebook', 'wall', ':p']\n",
      "1\t0.47136957\tb'case .. facebook wall :p'\n",
      "THE TWEET IS: @EmilyBett wishing you a happy birthday have an awesome fun filled day :D\n",
      "THE PROCESSED TWEET IS: ['wish', 'happi', 'birthday', 'awesom', 'fun', 'fill', 'day', ':d']\n",
      "1\t0.48064391\tb'wish happi birthday awesom fun fill day :d'\n",
      "THE TWEET IS: @BlooodofoIympus @johncrossmirror far from it. Being LFC fan makes me expert in spotting mental weakness and lack consistency :-)\n",
      "THE PROCESSED TWEET IS: ['far', 'lfc', 'fan', 'make', 'expert', 'spot', 'mental', 'weak', 'lack', 'consist', ':-)']\n",
      "1\t0.49758031\tb'far lfc fan make expert spot mental weak lack consist :-)'\n",
      "THE TWEET IS: Check this page belonging to one of our Watford Community Housing Trust enterprise cube particpants :-)... http://t.co/ZwaOnouXpo\n",
      "THE PROCESSED TWEET IS: ['check', 'page', 'belong', 'one', 'watford', 'commun', 'hous', 'trust', 'enterpris', 'cube', 'particp', ':-)', '...']\n",
      "1\t0.38070711\tb'check page belong one watford commun hous trust enterpris cube particp :-) ...'\n",
      "THE TWEET IS: @hufflepuffjimin omg thats such a sweet thing to say thank you :-) yeah i used to go to saudi arabia a lot because of my dad\n",
      "THE PROCESSED TWEET IS: ['omg', 'that', 'sweet', 'thing', 'say', 'thank', ':-)', 'yeah', 'use', 'go', 'saudi', 'arabia', 'lot', 'dad']\n",
      "1\t0.38619749\tb'omg that sweet thing say thank :-) yeah use go saudi arabia lot dad'\n",
      "THE TWEET IS: off to the park to get some sunlight : )\n",
      "THE PROCESSED TWEET IS: ['park', 'get', 'sunlight']\n",
      "1\t0.42441405\tb'park get sunlight'\n",
      "THE TWEET IS: @SaddestTiger @davedittell   Good night, Tiger!  Sweet furry dreams!   : ) xxoo\n",
      "THE PROCESSED TWEET IS: ['good', 'night', 'tiger', 'sweet', 'furri', 'dream', 'xxoo']\n",
      "1\t0.45906195\tb'good night tiger sweet furri dream xxoo'\n",
      "THE TWEET IS: Who wants to elevate from your position? Who wants a promotion! Who wants the favor of God and the favor of men... :) http://t.co/cOECx9BBNd\n",
      "THE PROCESSED TWEET IS: ['want', 'elev', 'posit', 'want', 'promot', 'want', 'favor', 'god', 'favor', 'men', '...', ':)']\n",
      "1\t0.39836550\tb'want elev posit want promot want favor god favor men ... :)'\n",
      "THE TWEET IS: I'm so insecure tonight :-)\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'insecur', 'tonight', ':-)']\n",
      "1\t0.42597179\tb\"i'm insecur tonight :-)\"\n",
      "THE TWEET IS: Match day Bitchessss !!!\n",
      "\n",
      "Real Madrid vs Man Shitty :D\n",
      "THE PROCESSED TWEET IS: ['match', 'day', 'bitchesss', 'real', 'madrid', 'vs', 'man', 'shitti', ':d']\n",
      "1\t0.48539816\tb'match day bitchesss real madrid vs man shitti :d'\n",
      "THE TWEET IS: at first I did love you, but now I just wanna fuck, late night thinking of you until I got a nut :-) :v\n",
      "\n",
      "\"look... http://t.co/8YhLcb16Lf\n",
      "THE PROCESSED TWEET IS: ['first', 'love', 'wanna', 'fuck', 'late', 'night', 'think', 'got', 'nut', ':-)', 'v', 'look', '...']\n",
      "1\t0.24818249\tb'first love wanna fuck late night think got nut :-) v look ...'\n",
      "THE TWEET IS: @gculloty87 @linda_regan Oh fab Gav she's a lovely lovely lady Linda talked to her a few times on here great actress :D X\n",
      "THE PROCESSED TWEET IS: ['oh', 'fab', 'gav', 'love', 'love', 'ladi', 'linda', 'talk', 'time', 'great', 'actress', ':d', 'x']\n",
      "1\t0.37908552\tb'oh fab gav love love ladi linda talk time great actress :d x'\n",
      "THE TWEET IS: @MCunleashed :D I can't sleep until I need to. If I try I just lay in bed bored\n",
      "THE PROCESSED TWEET IS: [':d', \"can't\", 'sleep', 'need', 'tri', 'lay', 'bed', 'bore']\n",
      "1\t0.37568917\tb\":d can't sleep need tri lay bed bore\"\n",
      "THE TWEET IS: goodnight ! i love Luke with all my heart :-) all my love ðŸ’œ\n",
      "THE PROCESSED TWEET IS: ['goodnight', 'love', 'luke', 'heart', ':-)', 'love', 'ðŸ’œ']\n",
      "1\t0.47746691\tb'goodnight love luke heart :-) love '\n",
      "THE TWEET IS: @Megalos_K I like your eyes :D\n",
      "THE PROCESSED TWEET IS: ['like', 'eye', ':d']\n",
      "1\t0.47208435\tb'like eye :d'\n",
      "THE TWEET IS: TY again dear Eva.\n",
      "I'm totally agree with you :-)))\n",
      "@anvy2446 @4HUMANITEEs @SexyAF12 @kikbella @adasamper @RachelLFilsoof\n",
      "Keep Smiling u all\n",
      "THE PROCESSED TWEET IS: ['ty', 'dear', 'eva', \"i'm\", 'total', 'agre', ':-)', 'keep', 'smile', 'u']\n",
      "1\t0.35781242\tb\"ty dear eva i'm total agre :-) keep smile u\"\n",
      "THE TWEET IS: On another note, found this in Camden Town... :D worked to. http://t.co/MDtJGcXopb\n",
      "THE PROCESSED TWEET IS: ['anoth', 'note', 'found', 'camden', 'town', '...', ':d', 'work']\n",
      "1\t0.37580246\tb'anoth note found camden town ... :d work'\n",
      "THE TWEET IS: @hansolotto with SCoups^^ they are for 17 like jren is for nuest!:D\n",
      "THE PROCESSED TWEET IS: ['scoup', '17', 'like', 'jren', 'nuest', ':d']\n",
      "1\t0.47554693\tb'scoup 17 like jren nuest :d'\n",
      "THE TWEET IS: Oh lovely lovelayyy! Thanks! It is ok about the kidney.. I don't want it anyway. :p https://t.co/ZbO0cjqhzG\n",
      "THE PROCESSED TWEET IS: ['oh', 'love', 'lovelayyy', 'thank', 'ok', 'kidney', '..', 'want', 'anyway', ':p']\n",
      "1\t0.32257683\tb'oh love lovelayyy thank ok kidney .. want anyway :p'\n",
      "THE TWEET IS: @msarosh Uff Itna Miss karhy thy ap :p\n",
      "THE PROCESSED TWEET IS: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
      "1\t0.39354477\tb'uff itna miss karhi thi ap :p'\n",
      "THE TWEET IS: @AlexCarranza21 I'm so sorry! I ran out with a friend after having a rough day. I'll try to stream on Saturday! :)\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'sorri', 'ran', 'friend', 'rough', 'day', \"i'll\", 'tri', 'stream', 'saturday', ':)']\n",
      "1\t0.49906314\tb\"i'm sorri ran friend rough day i'll tri stream saturday :)\"\n",
      "THE TWEET IS: @cinghh @imvnaj @BahetiRidham party cancel :p #BajrangiBhaijaanHighestWeek1\n",
      "THE PROCESSED TWEET IS: ['parti', 'cancel', ':p', 'bajrangibhaijaanhighestweek', '1']\n",
      "1\t0.49715241\tb'parti cancel :p bajrangibhaijaanhighestweek 1'\n",
      "THE TWEET IS: @SwitchingToSave Thanks for the follow :-) Hope you've had a great week?\n",
      "THE PROCESSED TWEET IS: ['thank', 'follow', ':-)', 'hope', 'great', 'week']\n",
      "1\t0.42059150\tb'thank follow :-) hope great week'\n",
      "THE TWEET IS: Can't sleep so much I want to do for all you love bugs but I only made 33 tokens never mind they are yours :)\n",
      "THE PROCESSED TWEET IS: [\"can't\", 'sleep', 'much', 'want', 'love', 'bug', 'made', '33', 'token', 'never', 'mind', ':)']\n",
      "1\t0.48076584\tb\"can't sleep much want love bug made 33 token never mind :)\"\n",
      "THE TWEET IS: Gamer Follow Train!\n",
      "Follow Me\n",
      "Retweet this\n",
      "Follow all who retweeted\n",
      "Gain active followers :) 110\n",
      "THE PROCESSED TWEET IS: ['gamer', 'follow', 'train', 'follow', 'retweet', 'follow', 'retweet', 'gain', 'activ', 'follow', ':)', '110']\n",
      "1\t0.40772075\tb'gamer follow train follow retweet follow retweet gain activ follow :) 110'\n",
      "THE TWEET IS: Here you behave or else u jump_Julias Malema :D\n",
      "THE PROCESSED TWEET IS: ['behav', 'els', 'u', 'jump_julia', 'malema', ':d']\n",
      "1\t0.48558407\tb'behav els u jump_julia malema :d'\n",
      "THE TWEET IS: @NASA nuf with the teasing already - show us the aliens now - everyday we seem to get closer to seeing our alien cousins :-)\n",
      "THE PROCESSED TWEET IS: ['nuf', 'teas', 'alreadi', 'show', 'us', 'alien', 'everyday', 'seem', 'get', 'closer', 'see', 'alien', 'cousin', ':-)']\n",
      "1\t0.39914567\tb'nuf teas alreadi show us alien everyday seem get closer see alien cousin :-)'\n",
      "THE TWEET IS: @SwgGuy Hah.... :D\n",
      "Don't say sorry...\n",
      "THE PROCESSED TWEET IS: ['hah', '...', ':d', 'say', 'sorri', '...']\n",
      "1\t0.25994246\tb'hah ... :d say sorri ...'\n",
      "THE TWEET IS: @KChenoweth Happy Birthday, Miss Chenoweth! Hope its a great one... have oodles of cake :)\n",
      "THE PROCESSED TWEET IS: ['happi', 'birthday', 'miss', 'chenoweth', 'hope', 'great', 'one', '...', 'oodl', 'cake', ':)']\n",
      "1\t0.46339150\tb'happi birthday miss chenoweth hope great one ... oodl cake :)'\n",
      "THE TWEET IS: That feeling when someone shares a review you worked hard on :D\n",
      "THE PROCESSED TWEET IS: ['feel', 'someon', 'share', 'review', 'work', 'hard', ':d']\n",
      "1\t0.41557817\tb'feel someon share review work hard :d'\n",
      "THE TWEET IS: Well buds, guess I'm going to bed, goodnight guys, see you in the morning, or whatever I woke up :)\n",
      "THE PROCESSED TWEET IS: ['well', 'bud', 'guess', \"i'm\", 'go', 'bed', 'goodnight', 'guy', 'see', 'morn', 'whatev', 'woke', ':)']\n",
      "1\t0.48714484\tb\"well bud guess i'm go bed goodnight guy see morn whatev woke :)\"\n",
      "THE TWEET IS: @SabrinaKeane it's not a bad thing!!! I think we all have weird faces!!! It's rad :-) thanks though!!\n",
      "THE PROCESSED TWEET IS: ['bad', 'thing', 'think', 'weird', 'face', 'rad', ':-)', 'thank', 'though']\n",
      "1\t0.45406516\tb'bad thing think weird face rad :-) thank though'\n",
      "THE TWEET IS: \"You make me alive, You make me suffer, You make me feel.. \n",
      "\n",
      "Addictive song i always sing in KARAOKE :-)..\n",
      "THE PROCESSED TWEET IS: ['make', 'aliv', 'make', 'suffer', 'make', 'feel', '..', 'addict', 'song', 'alway', 'sing', 'karaok', ':-)', '..']\n",
      "1\t0.29026840\tb'make aliv make suffer make feel .. addict song alway sing karaok :-) ..'\n",
      "THE TWEET IS: @SarahFHandley this one looks like it needs much more careful study I'll favourite it for later :-)\n",
      "THE PROCESSED TWEET IS: ['one', 'look', 'like', 'need', 'much', 'care', 'studi', \"i'll\", 'favourit', 'later', ':-)']\n",
      "1\t0.30413809\tb\"one look like need much care studi i'll favourit later :-)\"\n",
      "THE TWEET IS: @_Lineo_M_ LOL I sometimes tweet from @Coach_Yanga account lol but only on days when we are both home but I dont have a lot to say now :D\n",
      "THE PROCESSED TWEET IS: ['lol', 'sometim', 'tweet', 'account', 'lol', 'day', 'home', 'dont', 'lot', 'say', ':d']\n",
      "1\t0.40529757\tb'lol sometim tweet account lol day home dont lot say :d'\n",
      "THE TWEET IS: Gamer Follow Train!\n",
      "Follow Me\n",
      "Retweet this\n",
      "Follow all who retweeted\n",
      "Gain active followers :) 1\n",
      "THE PROCESSED TWEET IS: ['gamer', 'follow', 'train', 'follow', 'retweet', 'follow', 'retweet', 'gain', 'activ', 'follow', ':)', '1']\n",
      "1\t0.40426581\tb'gamer follow train follow retweet follow retweet gain activ follow :) 1'\n",
      "THE TWEET IS: 11:11 meet michael and hug him so tight and talk to him and tell him he's important and that I love him so much and make him smile :D\n",
      "THE PROCESSED TWEET IS: ['11:11', 'meet', 'michael', 'hug', 'tight', 'talk', 'tell', \"he'\", 'import', 'love', 'much', 'make', 'smile', ':d']\n",
      "1\t0.37919423\tb\"11:11 meet michael hug tight talk tell he' import love much make smile :d\"\n",
      "THE TWEET IS: me: as long as i feel comfortable im gonna wear what i want\n",
      "my mother: haha...that sounds nice...but no :-)\n",
      "THE PROCESSED TWEET IS: ['long', 'feel', 'comfort', 'im', 'gonna', 'wear', 'want', 'mother', 'haha', '...', 'sound', 'nice', '...', ':-)']\n",
      "1\t0.15226396\tb'long feel comfort im gonna wear want mother haha ... sound nice ... :-)'\n",
      "THE TWEET IS: @StormyKittyhawk You'll see me Saturday :p I'll see you then Stormy :D\n",
      "THE PROCESSED TWEET IS: ['see', 'saturday', ':p', \"i'll\", 'see', 'stormi', ':d']\n",
      "1\t0.47045819\tb\"see saturday :p i'll see stormi :d\"\n",
      "THE TWEET IS: Its time 2 party :D http://t.co/hjnT6v40eT\n",
      "THE PROCESSED TWEET IS: ['time', '2', 'parti', ':d']\n",
      "1\t0.47907742\tb'time 2 parti :d'\n",
      "THE TWEET IS: @em__scott haha I know!! Not messing about :D\n",
      "THE PROCESSED TWEET IS: ['haha', 'know', 'mess', ':d']\n",
      "1\t0.49579067\tb'haha know mess :d'\n",
      "THE TWEET IS: all i've done today is watch law &amp; order: svu. i love being sick :-)))\n",
      "THE PROCESSED TWEET IS: [\"i'v\", 'done', 'today', 'watch', 'law', 'order', 'svu', 'love', 'sick', ':-)']\n",
      "1\t0.40534624\tb\"i'v done today watch law order svu love sick :-)\"\n",
      "THE TWEET IS: As the morning wears on, its getting darker. Is it end of world day today instead of September? :-)\n",
      "THE PROCESSED TWEET IS: ['morn', 'wear', 'get', 'darker', 'end', 'world', 'day', 'today', 'instead', 'septemb', ':-)']\n",
      "1\t0.37853020\tb'morn wear get darker end world day today instead septemb :-)'\n",
      "THE TWEET IS: @nair_rinku -Its u with transparent...glasses..:-)\n",
      "THE PROCESSED TWEET IS: ['u', 'transpar', '...', 'glass', '..', ':-)']\n",
      "1\t0.34388202\tb'u transpar ... glass .. :-)'\n",
      "THE TWEET IS: @keab42 I rang in sick yesterday, then told them I'd be back in today. I'm better this morning anyway, and I have a day off on Sunday. :)\n",
      "THE PROCESSED TWEET IS: ['rang', 'sick', 'yesterday', 'told', \"i'd\", 'back', 'today', \"i'm\", 'better', 'morn', 'anyway', 'day', 'sunday', ':)']\n",
      "1\t0.48951160\tb\"rang sick yesterday told i'd back today i'm better morn anyway day sunday :)\"\n",
      "THE TWEET IS: @basementgalaxy Ping! I'm watching your TL like a hawk! :D\n",
      "THE PROCESSED TWEET IS: ['ping', \"i'm\", 'watch', 'tl', 'like', 'hawk', ':d']\n",
      "1\t0.33621297\tb\"ping i'm watch tl like hawk :d\"\n",
      "THE TWEET IS: @namcew make use of the masquerade mask!!!! Lol #zorroreturms :-)\n",
      "THE PROCESSED TWEET IS: ['make', 'use', 'masquerad', 'mask', 'lol', 'zorroreturm', ':-)']\n",
      "1\t0.49197526\tb'make use masquerad mask lol zorroreturm :-)'\n",
      "THE TWEET IS: ye to #Pk hay :p https://t.co/TSLYvAClux\n",
      "THE PROCESSED TWEET IS: ['ye', 'pk', 'hay', ':p']\n",
      "1\t0.49313521\tb'ye pk hay :p'\n",
      "THE TWEET IS: @ZerbuTabek Hi I'm only seeing workplace one in my venue list. I'm not sure how to fix this? Thanks :)\n",
      "THE PROCESSED TWEET IS: ['hi', \"i'm\", 'see', 'workplac', 'one', 'venu', 'list', \"i'm\", 'sure', 'fix', 'thank', ':)']\n",
      "1\t0.44388130\tb\"hi i'm see workplac one venu list i'm sure fix thank :)\"\n",
      "THE TWEET IS: Well this totally blew my mind this morning : ) https://t.co/jjXcm44YPJ\n",
      "THE PROCESSED TWEET IS: ['well', 'total', 'blew', 'mind', 'morn']\n",
      "1\t0.47287848\tb'well total blew mind morn'\n",
      "THE TWEET IS: @thevieweast Of course! Now I've been cited in an academic paper I feel I've arrived :-)\n",
      "THE PROCESSED TWEET IS: ['cours', \"i'v\", 'cite', 'academ', 'paper', 'feel', \"i'v\", 'arriv', ':-)']\n",
      "1\t0.42819514\tb\"cours i'v cite academ paper feel i'v arriv :-)\"\n",
      "THE TWEET IS: @colorlessmoemoe i beleaf in u :-)\n",
      "THE PROCESSED TWEET IS: ['beleaf', 'u', ':-)']\n",
      "1\t0.49102259\tb'beleaf u :-)'\n",
      "THE TWEET IS: @kevinngmingyuan peasant seats to watch a peasant team...I don't mind :p ahahha\n",
      "THE PROCESSED TWEET IS: ['peasant', 'seat', 'watch', 'peasant', 'team', '...', 'mind', ':p', 'ahahha']\n",
      "1\t0.36421311\tb'peasant seat watch peasant team ... mind :p ahahha'\n",
      "THE TWEET IS: pats jay : (\n",
      "THE PROCESSED TWEET IS: ['pat', 'jay']\n",
      "0\t0.50028908\tb'pat jay'\n"
     ]
    }
   ],
   "source": [
    "# Some error analysis done for you\n",
    "print('Label Predicted Tweet')\n",
    "for x,y in zip(test_x,test_y):\n",
    "    y_hat = predict_tweet(x, freqs, theta)\n",
    "\n",
    "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
    "        print('THE TWEET IS:', x)\n",
    "        print('THE PROCESSED TWEET IS:', process_tweet(x))\n",
    "        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in this specialization, we will see how we can use deep learning to improve the prediction performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Predict with your own tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ridicul', 'bright', 'movi', 'plot', 'terribl', 'sad', 'end']\n",
      "[[0.42055058]]\n",
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "# Feel free to change the tweet below\n",
    "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
    "print(process_tweet(my_tweet))\n",
    "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Positive sentiment')\n",
    "else: \n",
    "    print('Negative sentiment')"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "NLPC1-1"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
